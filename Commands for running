[training@localhost code]$ pwd
/home/training/Hadoop Map reduce Example/code

[training@localhost code]$ ls
mapper.py  mapper.py~  reducer.py  reducer.py~

[training@localhost code]$ chmod 777 mapper.py

[training@localhost code]$ chmod 777 reducer.py

[training@localhost code]$ ./mapper.py 
f1      f2	f3	f4	f5	f6
field2	f2	f5	f6	g7	f5
field1	f3	f5	g6	h6	f5
f3	f5
f5	g7
f5	h6

[training@localhost code]$ ls ../data
access_log.gz  purchases.txt
[training@localhost code]$ head -50 ../data/purchases.txt > testfile
[training@localhost code]$ head testfile 
2012-01-01	09:00	San Jose	Men's Clothing	214.05Amex
2012-01-01	09:00	Fort Worth	Women's Clothing	153.57	Visa
2012-01-01	09:00	San Diego	Music	66.08	Cash
2012-01-01	09:00	Pittsburgh	Pet Supplies	493.51Discover
2012-01-01	09:00	Omaha	Children's Clothing	235.63MasterCard
2012-01-01	09:00	Stockton	Men's Clothing	247.18MasterCard
2012-01-01	09:00	Austin	Cameras	379.6	Visa
2012-01-01	09:00	New York	Consumer Electronics	296.8	Cash
2012-01-01	09:00	Corpus Christi	Toys	25.38	Discover
2012-01-01	09:00	Fort Worth	Toys	213.88	Visa

# Here we are piping the testfile to the mapper code for execution

[training@localhost code]$ cat testfile | ./mapper.py 
San Jose	214.05
Fort Worth	153.57
San Diego	66.08
Pittsburgh	493.51
Omaha	235.63
Stockton	247.18
Austin	379.6
New York	296.8
Corpus Christi	25.38
Fort Worth	213.88
Las Vegas	53.26
Newark	39.75
Austin	469.63
Greensboro	290.82
San Francisco	260.65
Lincoln	136.9
Buffalo	483.82
San Jose	215.82
Boston	418.94
Houston	309.16
Las Vegas	93.39
Virginia Beach	376.11
Riverside	252.88
Tulsa	205.06
Reno	88.25
Chicago	31.08
Fort Wayne	370.55
San Bernardino	170.2
Madison	16.78
Austin	327.75
Portland	108.69
Riverside	15.41
Reno	80.46
Anchorage	298.86
Pittsburgh	475.26
Spokane	3.85
Spokane	287.65
Fresno	466.64
Omaha	255.68
Anchorage	6.38
Aurora	117.81
Philadelphia	351.31
Fremont	222.61
Anchorage	22.36
Norfolk	189.01
Chandler	414.08
Minneapolis	182.05
Honolulu	345.18
Indianapolis	135.96
Chandler	344.09

# Simuplation of the Hadoop steps on the linux terminal using inbulid unix commands

[training@localhost code]$ cat testfile | ./mapper.py | sort | ./reducer.py 
Anchorage	327.6
Aurora	117.81
Austin	1176.98
Boston	418.94
Buffalo	483.82
Chandler	758.17
Chicago	31.08
Corpus Christi	25.38
Fort Wayne	370.55
Fort Worth	367.45
Fremont	222.61
Fresno	466.64
Greensboro	290.82
Honolulu	345.18
Houston	309.16
Indianapolis	135.96
Las Vegas	146.65
Lincoln	136.9
Madison	16.78
Minneapolis	182.05
Newark	39.75
New York	296.8
Norfolk	189.01
Omaha	491.31
Philadelphia	351.31
Pittsburgh	968.77
Portland	108.69
Reno	168.71
Riverside	268.29
San Bernardino	170.2
San Diego	66.08
San Francisco	260.65
San Jose	429.87
Spokane	291.5
Stockton	247.18
Tulsa	205.06
Virginia Beach	376.11

[training@localhost code]$ hadoop fs -put testfile 
[training@localhost code]$ hadoop fs -ls
Found 2 items
drwxr-xr-x   - training supergroup          0 2014-04-30 04:00 myinput
-rw-r--r--   1 training supergroup       2501 2014-05-18 10:35 testfile

# Hear the "outputfile" is afolder name where all the output will be stored

[training@localhost code]$ run_mapreduce mapper.py reducer.py testfile outputfile
packageJobJar: [mapper.py, reducer.py, /tmp/hadoop-training/hadoop-unjar2902328226788796732/] [] /tmp/streamjob8953937423926738832.jar tmpDir=null
14/05/18 10:36:49 WARN mapred.JobClient: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
14/05/18 10:36:49 WARN snappy.LoadSnappy: Snappy native library is available
14/05/18 10:36:49 INFO snappy.LoadSnappy: Snappy native library loaded
14/05/18 10:36:49 INFO mapred.FileInputFormat: Total input paths to process : 1
14/05/18 10:36:49 INFO streaming.StreamJob: getLocalDirs(): [/var/lib/hadoop-hdfs/cache/training/mapred/local]
14/05/18 10:36:49 INFO streaming.StreamJob: Running job: job_201405180903_0002
14/05/18 10:36:49 INFO streaming.StreamJob: To kill this job, run:
14/05/18 10:36:49 INFO streaming.StreamJob: UNDEF/bin/hadoop job  -Dmapred.job.tracker=0.0.0.0:8021 -kill job_201405180903_0002
14/05/18 10:36:49 INFO streaming.StreamJob: Tracking URL: http://0.0.0.0:50030/jobdetails.jsp?jobid=job_201405180903_0002
14/05/18 10:36:50 INFO streaming.StreamJob:  map 0%  reduce 0%
14/05/18 10:36:55 INFO streaming.StreamJob:  map 100%  reduce 0%
14/05/18 10:36:59 INFO streaming.StreamJob:  map 100%  reduce 100%
14/05/18 10:37:02 INFO streaming.StreamJob: Job complete: job_201405180903_0002
14/05/18 10:37:02 INFO streaming.StreamJob: Output: outputfile

[training@localhost code]$ hadoop fs -ls outputfile
Found 3 items
-rw-r--r--   1 training supergroup          0 2014-05-18 10:37 outputfile/_SUCCESS
drwxr-xr-x   - training supergroup          0 2014-05-18 10:36 outputfile/_logs
-rw-r--r--   1 training supergroup        601 2014-05-18 10:36 outputfile/part-00000


[training@localhost code]$ hadoop fs -text outputfile/part-00000
14/05/18 10:40:16 WARN snappy.LoadSnappy: Snappy native library is available
14/05/18 10:40:16 INFO snappy.LoadSnappy: Snappy native library loaded
Anchorage	327.6
Aurora	117.81
Austin	1176.98
Boston	418.94
Buffalo	483.82
Chandler	758.17
Chicago	31.08
Corpus Christi	25.38
Fort Wayne	370.55
Fort Worth	367.45
Fremont	222.61
Fresno	466.64
Greensboro	290.82
Honolulu	345.18
Houston	309.16
Indianapolis	135.96
Las Vegas	146.65
Lincoln	136.9
Madison	16.78
Minneapolis	182.05
New York	296.8
Newark	39.75
Norfolk	189.01
Omaha	491.31
Philadelphia	351.31
Pittsburgh	968.77
Portland	108.69
Reno	168.71
Riverside	268.29
San Bernardino	170.2
San Diego	66.08
San Francisco	260.65
San Jose	429.87
Spokane	291.5
Stockton	247.18
Tulsa	205.06
Virginia Beach	376.11


